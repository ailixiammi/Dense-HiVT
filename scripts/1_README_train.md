# Dense-HiVT è®­ç»ƒè„šæœ¬ä½¿ç”¨æ–‡æ¡£

## ğŸ“‹ æ¦‚è¿°

`train.py` æ˜¯ Dense-HiVT æ¨¡å‹çš„è®­ç»ƒè„šæœ¬,å®ç°äº†é«˜æ•ˆçš„ç«¯åˆ°ç«¯è®­ç»ƒæµç¨‹ã€‚è¯¥è„šæœ¬é’ˆå¯¹ GPU è®­ç»ƒè¿›è¡Œäº†ä¼˜åŒ–,æ”¯æŒè‡ªåŠ¨æ··åˆç²¾åº¦(AMP)ã€å­¦ä¹ ç‡é¢„çƒ­ã€æ¢¯åº¦è£å‰ªç­‰ç°ä»£è®­ç»ƒæŠ€æœ¯ã€‚

## ğŸ¯ æ ¸å¿ƒç‰¹æ€§

### 1. è‡ªåŠ¨æ··åˆç²¾åº¦è®­ç»ƒ (AMP)
- **Tensor Core åŠ é€Ÿ**ï¼šå……åˆ†åˆ©ç”¨ RTX ç³»åˆ— GPU çš„ FP16 è®¡ç®—èƒ½åŠ›
- **GradScaler**ï¼šè‡ªåŠ¨å¤„ç†æ¢¯åº¦ç¼©æ”¾,é˜²æ­¢ä¸‹æº¢
- **å†…å­˜ä¼˜åŒ–**ï¼šç›¸æ¯” FP32 è®­ç»ƒå¯èŠ‚çœçº¦ 40% æ˜¾å­˜

### 2. å…ˆè¿›çš„ä¼˜åŒ–ç­–ç•¥

**ä¼˜åŒ–å™¨ï¼šAdamW**
- è§£è€¦æƒé‡è¡°å‡,æ”¹å–„æ³›åŒ–æ€§èƒ½
- é»˜è®¤å‚æ•°ï¼šlr=5e-4, weight_decay=1e-4

**å­¦ä¹ ç‡è°ƒåº¦ï¼šWarmup + Cosine Annealing**
- **Phase 1 (Warmup)**ï¼šå‰ 5 ä¸ª epoch ä» 5e-6 çº¿æ€§å¢é•¿åˆ° 5e-4
- **Phase 2 (Cosine)**ï¼šåç»­ epoch ä½™å¼¦è¡°å‡åˆ° 1e-6
- é¿å…è®­ç»ƒåˆæœŸçš„æ¢¯åº¦çˆ†ç‚¸,åæœŸç²¾ç»†è°ƒä¼˜

**æ¢¯åº¦è£å‰ª**
- Max Norm = 5.0
- é˜²æ­¢ Laplace NLL Loss å¼•èµ·çš„æ¢¯åº¦çˆ†ç‚¸

### 3. å®Œå–„çš„è®­ç»ƒç›‘æ§

**TensorBoard æ—¥å¿—**
- å®æ—¶è®°å½•è®­ç»ƒ/éªŒè¯æŸå¤±
- å­¦ä¹ ç‡æ›²çº¿è¿½è¸ª
- è¯„æµ‹æŒ‡æ ‡å¯è§†åŒ– (minADE, minFDE, MR)

**ç»ˆç«¯è¿›åº¦æ¡**
- å®æ—¶æ˜¾ç¤ºè®­ç»ƒè¿›åº¦
- Loss åˆ†è§£ (Reg Loss + Cls Loss)
- å½“å‰å­¦ä¹ ç‡

### 4. è‡ªåŠ¨åŒ–æ¨¡å‹ç®¡ç†

**Checkpoint ä¿å­˜ç­–ç•¥**
- `latest.pth`ï¼šæ¯ä¸ª epoch è‡ªåŠ¨æ›´æ–°
- `best_dense_hivt.pth`ï¼šåŸºäºéªŒè¯é›† minFDE ä¿å­˜æœ€ä½³æ¨¡å‹
- å®Œæ•´ä¿å­˜è®­ç»ƒçŠ¶æ€(æ¨¡å‹ã€ä¼˜åŒ–å™¨ã€è°ƒåº¦å™¨ã€Scaler)

## ğŸš€ å¿«é€Ÿå¼€å§‹

### åŸºæœ¬è®­ç»ƒå‘½ä»¤

```bash
python scripts/train.py \
    --train_dir /path/to/processed/train \
    --val_dir /path/to/processed/val \
    --output_dir outputs
```

### ä½¿ç”¨ç¤ºä¾‹æ•°æ®è·¯å¾„

```bash
# æœåŠ¡å™¨ç¯å¢ƒ
python scripts/train.py \
    --train_dir /root/devdata/Dense-HiVT/data/processed/train \
    --val_dir /root/devdata/Dense-HiVT/data/processed/val \
    --batch_size 64 \
    --epochs 64
```

## âš™ï¸ å‚æ•°è¯´æ˜

### æ•°æ®ç›¸å…³å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `--train_dir` | str | å¿…éœ€ | è®­ç»ƒé›†ç›®å½• (.pt æ–‡ä»¶) |
| `--val_dir` | str | å¿…éœ€ | éªŒè¯é›†ç›®å½• (.pt æ–‡ä»¶) |
| `--output_dir` | str | `outputs` | è¾“å‡ºç›®å½•(ä¿å­˜åœ¨é¡¹ç›®æ ¹ç›®å½•) |

### æ¨¡å‹è¶…å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `--embed_dim` | int | 128 | Transformer åµŒå…¥ç»´åº¦ |
| `--num_heads` | int | 8 | Multi-Head Attention å¤´æ•° |
| `--num_local_encoder_layers` | int | 4 | Local Encoder å±‚æ•° |
| `--num_global_interactor_layers` | int | 3 | Global Interactor å±‚æ•° |
| `--num_decoder_layers` | int | 4 | Decoder å±‚æ•° |
| `--dropout` | float | 0.1 | Dropout æ¦‚ç‡ |
| `--num_modes` | int | 6 | å¤šæ¨¡æ€é¢„æµ‹æ•°é‡ |
| `--future_steps` | int | 30 | é¢„æµ‹æœªæ¥æ—¶é—´æ­¥ (3ç§’) |

### è®­ç»ƒè¶…å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `--epochs` | int | 64 | è®­ç»ƒæ€»è½®æ•° |
| `--batch_size` | int | 64 | æ‰¹æ¬¡å¤§å° |
| `--lr` | float | 5e-4 | åŸºç¡€å­¦ä¹ ç‡ |
| `--lr_min` | float | 1e-6 | æœ€å°å­¦ä¹ ç‡ (Cosine) |
| `--warmup_epochs` | int | 5 | å­¦ä¹ ç‡é¢„çƒ­è½®æ•° |
| `--weight_decay` | float | 1e-4 | æƒé‡è¡°å‡ç³»æ•° |
| `--grad_clip_norm` | float | 5.0 | æ¢¯åº¦è£å‰ªé˜ˆå€¼ |
| `--use_amp` | bool | true | ä½¿ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦ |

### DataLoader é…ç½®

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `--num_workers` | int | 8 | æ•°æ®åŠ è½½è¿›ç¨‹æ•° |
| `--pin_memory` | bool | true | ä½¿ç”¨ Pinned Memory |
| `--prefetch_factor` | int | 2 | é¢„å–æ‰¹æ¬¡æ•° |

## ğŸ“Š è¿›é˜¶ç”¨æ³•

### 1. è°ƒæ•´æ‰¹æ¬¡å¤§å°

æ ¹æ® GPU æ˜¾å­˜è°ƒæ•´ batch sizeï¼š

```bash
# RTX 4090 (24GB) - æ¨è
python scripts/train.py \
    --train_dir /path/to/train \
    --val_dir /path/to/val \
    --batch_size 64

# RTX 3090 (24GB)
python scripts/train.py \
    --train_dir /path/to/train \
    --val_dir /path/to/val \
    --batch_size 48

# RTX 3080 (10GB)
python scripts/train.py \
    --train_dir /path/to/train \
    --val_dir /path/to/val \
    --batch_size 24
```

### 2. è°ƒæ•´å­¦ä¹ ç‡ç­–ç•¥

```bash
# æ›´æ¿€è¿›çš„å­¦ä¹ ç‡
python scripts/train.py \
    --train_dir /path/to/train \
    --val_dir /path/to/val \
    --lr 1e-3 \
    --warmup_epochs 10

# æ›´ä¿å®ˆçš„å­¦ä¹ ç‡
python scripts/train.py \
    --train_dir /path/to/train \
    --val_dir /path/to/val \
    --lr 1e-4 \
    --lr_min 1e-7 \
    --warmup_epochs 3
```

### 3. é•¿æ—¶é—´è®­ç»ƒ

```bash
python scripts/train.py \
    --train_dir /path/to/train \
    --val_dir /path/to/val \
    --epochs 128 \
    --lr 5e-4 \
    --lr_min 5e-7
```

### 4. å…³é—­ AMP (è°ƒè¯•ç”¨)

```bash
python scripts/train.py \
    --train_dir /path/to/train \
    --val_dir /path/to/val \
    --use_amp false
```

### 5. è°ƒæ•´æ•°æ®åŠ è½½æ€§èƒ½

```bash
# é«˜æ€§èƒ½ NVMe SSD
python scripts/train.py \
    --train_dir /path/to/train \
    --val_dir /path/to/val \
    --num_workers 16 \
    --prefetch_factor 4

# ä½é€Ÿæœºæ¢°ç¡¬ç›˜
python scripts/train.py \
    --train_dir /path/to/train \
    --val_dir /path/to/val \
    --num_workers 4 \
    --prefetch_factor 1
```

## ğŸ“ è¾“å‡ºç›®å½•ç»“æ„

```
outputs/
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ latest.pth              # æœ€æ–° Checkpoint
â”‚   â””â”€â”€ best_dense_hivt.pth     # æœ€ä½³æ¨¡å‹ (åŸºäº Val minFDE)
â”‚
â””â”€â”€ logs/
    â”œâ”€â”€ run_20260220_143052/    # TensorBoard æ—¥å¿— (å¸¦æ—¶é—´æˆ³)
    â”‚   â””â”€â”€ events.out.tfevents.*
    â”œâ”€â”€ run_20260220_180432/
    â””â”€â”€ run_20260221_091523/
```

### Checkpoint å†…å®¹

```python
checkpoint = {
    'epoch': å½“å‰è½®æ•°,
    'model_state_dict': æ¨¡å‹æƒé‡,
    'optimizer_state_dict': ä¼˜åŒ–å™¨çŠ¶æ€,
    'scheduler_state_dict': å­¦ä¹ ç‡è°ƒåº¦å™¨çŠ¶æ€,
    'scaler_state_dict': AMP Scaler çŠ¶æ€,
    'best_val_fde': å†å²æœ€ä½³ minFDE,
    'val_metrics': {
        'minADE': å¹³å‡ä½ç§»è¯¯å·®,
        'minFDE': æœ€ç»ˆä½ç§»è¯¯å·®,
        'MR': é”™è¿‡ç‡
    },
    'args': è®­ç»ƒå‚æ•°é…ç½®
}
```

## ğŸ” è®­ç»ƒç›‘æ§

### 1. å¯åŠ¨ TensorBoard

```bash
# å¯åŠ¨ TensorBoard
tensorboard --logdir outputs/logs --port 6006

# åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€
# http://localhost:6006
```

### 2. å…³é”®æŒ‡æ ‡è§£è¯»

**è®­ç»ƒæŒ‡æ ‡ (Scalars)**

- `Train/Loss`ï¼šæ€»æŸå¤± = Reg Loss + Cls Loss
- `Train/RegLoss`ï¼šå›å½’æŸå¤± (Laplace NLL)
- `Train/ClsLoss`ï¼šåˆ†ç±»æŸå¤± (äº¤å‰ç†µ)
- `Train/LR`ï¼šå½“å‰å­¦ä¹ ç‡

**éªŒè¯æŒ‡æ ‡ (Scalars)**

- `Epoch/Val_minADE`ï¼šæœ€å°å¹³å‡ä½ç§»è¯¯å·® (ç±³)
  - è¡¡é‡æ•´ä½“è½¨è¿¹é¢„æµ‹ç²¾åº¦
  - **ç›®æ ‡**ï¼š< 1.0 ç±³ (SOTA)
  
- `Epoch/Val_minFDE`ï¼šæœ€å°æœ€ç»ˆä½ç§»è¯¯å·® (ç±³)
  - è¡¡é‡ 3 ç§’åçš„ä½ç½®é¢„æµ‹ç²¾åº¦
  - **ç›®æ ‡**ï¼š< 1.5 ç±³ (SOTA)
  
- `Epoch/Val_MR`ï¼šé”™è¿‡ç‡ (%)
  - FDE > 2.0 ç±³çš„æ ·æœ¬æ¯”ä¾‹
  - **ç›®æ ‡**ï¼š< 10% (SOTA)

**å­¦ä¹ ç‡æ›²çº¿**

- `Epoch/LR`ï¼šå­¦ä¹ ç‡å˜åŒ–
  - Epoch 1-5ï¼šçº¿æ€§å¢é•¿ (Warmup)
  - Epoch 6-64ï¼šä½™å¼¦è¡°å‡

### 3. è®­ç»ƒæ›²çº¿è¯Šæ–­

**æ­£å¸¸è®­ç»ƒæ›²çº¿**
- Train Loss å¹³ç¨³ä¸‹é™
- Val minFDE åœ¨å‰ 20 epoch å¿«é€Ÿä¸‹é™
- Epoch 30-50 è¿›å…¥å¹³å°æœŸ,ç¼“æ…¢ä¼˜åŒ–

**è¿‡æ‹Ÿåˆä¿¡å·**
- Train Loss æŒç»­ä¸‹é™,Val minFDE ä¸Šå‡
- è§£å†³æ–¹æ¡ˆï¼šå¢å¤§ dropout æˆ– weight_decay

**æ¬ æ‹Ÿåˆä¿¡å·**
- Train Loss å’Œ Val minFDE éƒ½å¾ˆé«˜
- è§£å†³æ–¹æ¡ˆï¼šå¢å¤§æ¨¡å‹å®¹é‡æˆ–è®­ç»ƒè½®æ•°

**å­¦ä¹ ç‡è¿‡å¤§**
- Loss å‰§çƒˆéœ‡è¡
- è§£å†³æ–¹æ¡ˆï¼šé™ä½ `--lr` æˆ–å¢åŠ  `--warmup_epochs`

## ğŸ’¡ è®­ç»ƒæŠ€å·§

### 1. å­¦ä¹ ç‡è°ƒä¼˜

**Warmup çš„é‡è¦æ€§**
- é˜²æ­¢è®­ç»ƒåˆæœŸæ¢¯åº¦çˆ†ç‚¸
- ç»™ BatchNorm ç»Ÿè®¡é‡ç¨³å®šçš„åˆå§‹åŒ–æ—¶é—´
- å»ºè®® warmup_epochs = æ€» epochs çš„ 5-10%

**Cosine Annealing ä¼˜åŠ¿**
- åæœŸå­¦ä¹ ç‡é€æ¸é™ä½,æœ‰åŠ©äºæ”¶æ•›åˆ°æ›´å¥½çš„å±€éƒ¨æœ€ä¼˜
- é¿å… Step Decay çš„çªç„¶ä¸‹é™å¯¼è‡´çš„éœ‡è¡

### 2. æ‰¹æ¬¡å¤§å°æƒè¡¡

**å¤§æ‰¹æ¬¡ (64+)**
- âœ… è®­ç»ƒé€Ÿåº¦å¿«
- âœ… æ¢¯åº¦ä¼°è®¡æ›´ç¨³å®š
- âŒ éœ€è¦æ›´å¤šæ˜¾å­˜
- âŒ å¯èƒ½æ³›åŒ–æ€§èƒ½ç•¥å·®

**å°æ‰¹æ¬¡ (16-32)**
- âœ… æ˜¾å­˜å ç”¨ä½
- âœ… å¯èƒ½æ³›åŒ–æ€§èƒ½æ›´å¥½
- âŒ è®­ç»ƒé€Ÿåº¦æ…¢
- âŒ æ¢¯åº¦å™ªå£°å¤§

**å»ºè®®**ï¼šå°½é‡ç”¨å¤§æ‰¹æ¬¡,ä½†ä¿æŒ `lr âˆ âˆšbatch_size`

### 3. AMP ä½¿ç”¨å»ºè®®

**ä½•æ—¶ä½¿ç”¨ AMP**
- âœ… RTX 20/30/40 ç³»åˆ— GPU
- âœ… æ­£å¸¸è®­ç»ƒåœºæ™¯
- âœ… æ˜¾å­˜å—é™æ—¶

**ä½•æ—¶å…³é—­ AMP**
- âŒ è°ƒè¯•æ¨¡å‹æ—¶ (é¿å…ç²¾åº¦é—®é¢˜å¹²æ‰°)
- âŒ å‡ºç° NaN/Inf æ—¶
- âŒ GTX ç³»åˆ— GPU (æ—  Tensor Core)

### 4. æ¢¯åº¦è£å‰ª

**ä¸ºä»€ä¹ˆéœ€è¦**
- Laplace NLL Loss åœ¨ scale å‚æ•°æ¥è¿‘ 0 æ—¶æ¢¯åº¦ä¼šçˆ†ç‚¸
- å¤šæ¨¡æ€é¢„æµ‹ä¸­æŸäº›æ¨¡å¼å¯èƒ½äº§ç”Ÿæç«¯æ¢¯åº¦

**è°ƒä¼˜å»ºè®®**
- é»˜è®¤ 5.0 é€‚ç”¨äºå¤§å¤šæ•°åœºæ™¯
- å¦‚æœä»æœ‰æ¢¯åº¦çˆ†ç‚¸,é™ä½åˆ° 1.0-3.0
- å¦‚æœè®­ç»ƒè¿‡äºä¿å®ˆ,å¢å¤§åˆ° 10.0

### 5. æ•°æ®åŠ è½½ä¼˜åŒ–

**num_workers è®¾ç½®**
- **CPU æ ¸å¿ƒæ•° â‰¥ 16**ï¼š`num_workers = 8-16`
- **CPU æ ¸å¿ƒæ•° 8-16**ï¼š`num_workers = 4-8`
- **CPU æ ¸å¿ƒæ•° < 8**ï¼š`num_workers = 2-4`

**prefetch_factor**
- **NVMe SSD**ï¼š2-4 (I/O ä¸æ˜¯ç“¶é¢ˆ)
- **SATA SSD**ï¼š2
- **HDD**ï¼š1 (é¿å…è¿‡åº¦é¢„å–)

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. æ˜¾å­˜å ç”¨

**å•å¡æ˜¾å­˜éœ€æ±‚**

| Batch Size | æ¨¡å‹å‚æ•° | æ˜¾å­˜å ç”¨ (AMP) | æ˜¾å­˜å ç”¨ (FP32) |
|------------|----------|----------------|-----------------|
| 16 | ~10M | ~6 GB | ~10 GB |
| 32 | ~10M | ~10 GB | ~18 GB |
| 64 | ~10M | ~18 GB | ~32 GB |

**æ˜¾å­˜ä¸è¶³è§£å†³æ–¹æ¡ˆ**
1. å‡å° `--batch_size`
2. å‡å° `--embed_dim` (å¦‚ 128 â†’ 96)
3. ç¡®ä¿ `--use_amp` å¼€å¯
4. å‡å° `--num_global_interactor_layers`

### 2. è®­ç»ƒæ—¶é—´ä¼°ç®—

**è®­ç»ƒé€Ÿåº¦** (RTX 4090 + Batch 64)
- æ¯ä¸ª epochï¼š~8-12 åˆ†é’Ÿ
- 64 epochsï¼š~9-13 å°æ—¶

**å½±å“å› ç´ **
- DataLoader æ•ˆç‡ (ç£ç›˜ I/O)
- GPU åˆ©ç”¨ç‡
- éªŒè¯é›†å¤§å°

### 3. æ–­ç‚¹ç»­è®­

ä» Checkpoint æ¢å¤è®­ç»ƒï¼š

```python
# ä¿®æ”¹ train.pyï¼Œåœ¨ TrainingEngine.__init__ ä¸­æ·»åŠ ï¼š
if args.resume_from:
    checkpoint = torch.load(args.resume_from)
    self.model.load_state_dict(checkpoint['model_state_dict'])
    self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
    self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
    self.scaler.load_state_dict(checkpoint['scaler_state_dict'])
    self.current_epoch = checkpoint['epoch']
    self.best_val_fde = checkpoint['best_val_fde']
    print(f"âœ“ ä» Epoch {self.current_epoch} æ¢å¤è®­ç»ƒ")
```

### 4. å¤š GPU è®­ç»ƒ

å½“å‰è„šæœ¬ä»…æ”¯æŒå• GPU,å¦‚éœ€å¤š GPU è®­ç»ƒ,éœ€è¦ä½¿ç”¨ `torch.nn.DataParallel` æˆ– `DistributedDataParallel` åŒ…è£…æ¨¡å‹ã€‚

## ğŸ› å¸¸è§é—®é¢˜

### Q1: CUDA Out of Memory

**é”™è¯¯ä¿¡æ¯ï¼š** `RuntimeError: CUDA out of memory`

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# æ–¹æ¡ˆ 1: å‡å°æ‰¹æ¬¡å¤§å°
python scripts/train.py --batch_size 32

# æ–¹æ¡ˆ 2: å‡å°æ¨¡å‹å°ºå¯¸
python scripts/train.py --embed_dim 96 --num_global_interactor_layers 2

# æ–¹æ¡ˆ 3: æ¸…ç©º GPU ç¼“å­˜åé‡è¯•
nvidia-smi  # æŸ¥çœ‹ GPU å ç”¨
```

### Q2: Loss å‡ºç° NaN

**åŸå› ï¼š**
1. å­¦ä¹ ç‡è¿‡å¤§
2. æ¢¯åº¦çˆ†ç‚¸
3. æ•°æ®å¼‚å¸¸ (åŒ…å« NaN/Inf)

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# é™ä½å­¦ä¹ ç‡
python scripts/train.py --lr 1e-4

# åŠ å¼ºæ¢¯åº¦è£å‰ª
python scripts/train.py --grad_clip_norm 1.0

# å…³é—­ AMP (æ’æŸ¥ç²¾åº¦é—®é¢˜)
python scripts/train.py --use_amp false
```

### Q3: è®­ç»ƒé€Ÿåº¦æ…¢

**åŸå› åˆ†æï¼š**
1. DataLoader æˆä¸ºç“¶é¢ˆ (CPU æˆ–ç£ç›˜ I/O)
2. GPU åˆ©ç”¨ç‡ä½

**ä¼˜åŒ–æ–¹æ¡ˆï¼š**
```bash
# å¢åŠ æ•°æ®åŠ è½½è¿›ç¨‹
python scripts/train.py --num_workers 16 --prefetch_factor 4

# æ£€æŸ¥ GPU åˆ©ç”¨ç‡
nvidia-smi dmon -i 0 -s u  # å®æ—¶ç›‘æ§
```

### Q4: éªŒè¯æŒ‡æ ‡ä¸æ”¶æ•›

**å¯èƒ½åŸå› ï¼š**
1. å­¦ä¹ ç‡è¿‡å¤§æˆ–è¿‡å°
2. æ¨¡å‹å®¹é‡ä¸è¶³
3. æ•°æ®è´¨é‡é—®é¢˜

**æ’æŸ¥æ­¥éª¤ï¼š**
1. æ£€æŸ¥ TensorBoard ä¸­çš„å­¦ä¹ ç‡æ›²çº¿
2. å¯¹æ¯”è®­ç»ƒé›†å’ŒéªŒè¯é›† Loss
3. å¯è§†åŒ–é¢„æµ‹ç»“æœ (ä½¿ç”¨ `eval.py`)

### Q5: æœ€ä½³æ¨¡å‹æ²¡æœ‰ä¿å­˜

**åŸå› ï¼š** éªŒè¯é›† minFDE ä»æœªä½äºåˆå§‹çš„ `float('inf')`

**æ£€æŸ¥ï¼š**
```bash
# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
cat outputs/logs/run_*/events.out.tfevents.* | grep minFDE

# æ‰‹åŠ¨æ£€æŸ¥ Checkpoint
python -c "import torch; ckpt = torch.load('outputs/checkpoints/latest.pth'); print(ckpt['val_metrics'])"
```

## ğŸ“š ä»£ç ç»“æ„

```python
scripts/train.py
â”‚
â”œâ”€â”€ TrainingEngine                    # è®­ç»ƒå¼•æ“ä¸»ç±»
â”‚   â”œâ”€â”€ __init__()                   # åˆå§‹åŒ–æ¨¡å‹ã€ä¼˜åŒ–å™¨ã€è°ƒåº¦å™¨
â”‚   â”œâ”€â”€ train_one_epoch()            # å• Epoch è®­ç»ƒå¾ªç¯
â”‚   â”œâ”€â”€ validate()                   # éªŒè¯é›†è¯„ä¼°
â”‚   â”œâ”€â”€ save_checkpoint()            # Checkpoint ä¿å­˜
â”‚   â””â”€â”€ train()                      # ä¸»è®­ç»ƒå¾ªç¯
â”‚
â”œâ”€â”€ parse_args()                      # å‘½ä»¤è¡Œå‚æ•°è§£æ
â””â”€â”€ main()                           # å…¥å£å‡½æ•°
```

### TrainingEngine æ ¸å¿ƒæµç¨‹

```
1. __init__
   â”œâ”€â”€ åˆå§‹åŒ–æ¨¡å‹ (DenseHiVT)
   â”œâ”€â”€ åˆå§‹åŒ–æŸå¤±å‡½æ•° (DenseHiVTLoss)
   â”œâ”€â”€ åˆå§‹åŒ–ä¼˜åŒ–å™¨ (AdamW)
   â”œâ”€â”€ åˆå§‹åŒ–å­¦ä¹ ç‡è°ƒåº¦å™¨ (Warmup + Cosine)
   â”œâ”€â”€ åˆå§‹åŒ– GradScaler (AMP)
   â””â”€â”€ åˆ›å»ºè¾“å‡ºç›®å½•å’Œ TensorBoard Writer

2. train()
   â””â”€â”€ for epoch in range(1, epochs+1):
       â”œâ”€â”€ train_one_epoch()
       â”‚   â””â”€â”€ for batch in train_loader:
       â”‚       â”œâ”€â”€ å‰å‘ä¼ æ’­ (with autocast)
       â”‚       â”œâ”€â”€ è®¡ç®—æŸå¤±
       â”‚       â”œâ”€â”€ åå‘ä¼ æ’­ + æ¢¯åº¦è£å‰ª
       â”‚       â””â”€â”€ è®°å½•åˆ° TensorBoard
       â”‚
       â”œâ”€â”€ validate()
       â”‚   â””â”€â”€ for batch in val_loader:
       â”‚       â”œâ”€â”€ å‰å‘ä¼ æ’­ (with autocast)
       â”‚       â”œâ”€â”€ è®¡ç®—è¯„æµ‹æŒ‡æ ‡ (minADE, minFDE, MR)
       â”‚       â””â”€â”€ ç´¯ç§¯å¹¶è¿”å›å¹³å‡å€¼
       â”‚
       â”œâ”€â”€ scheduler.step()         # æ›´æ–°å­¦ä¹ ç‡
       â”œâ”€â”€ è®°å½• Epoch çº§æŒ‡æ ‡
       â”œâ”€â”€ æ£€æŸ¥æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹
       â””â”€â”€ save_checkpoint()         # ä¿å­˜æ¨¡å‹
```

## ğŸ“ˆ æ€§èƒ½åŸºå‡†

**å‚è€ƒæ€§èƒ½** (Argoverse 1.1 éªŒè¯é›†)

| Epoch | minADE (m) | minFDE (m) | MR (%) | è®­ç»ƒæ—¶é•¿ |
|-------|------------|------------|--------|----------|
| 10    | ~1.8       | ~2.8       | ~25%   | ~1.5 å°æ—¶ |
| 30    | ~1.2       | ~1.9       | ~15%   | ~5 å°æ—¶ |
| 64    | ~0.9       | ~1.4       | ~9%    | ~10 å°æ—¶ |

**SOTA å¯¹æ¯”** (åŸå§‹ HiVT)
- minADE: 0.90 m
- minFDE: 1.39 m
- MR: 8.1%

## ğŸ“ è®­ç»ƒæ—¥å¿—ç¤ºä¾‹

```
================================================================================
                           å¼€å§‹è®­ç»ƒ
================================================================================

æ€» Epochs: 64
è®­ç»ƒé›†å¤§å°: 205942 æ ·æœ¬
éªŒè¯é›†å¤§å°: 39472 æ ·æœ¬
Base LR: 0.0005
Warmup Epochs: 5 (ä» 5.00e-06 å¢é•¿åˆ° 5.00e-04)
Min LR: 1e-06
Weight Decay: 0.0001
Gradient Clip Norm: 5.0
AMP å¯ç”¨: True

================================================================================

Epoch 1/64 [Train] |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3218/3218 [08:32<00:00, 6.28it/s]
Epoch 1/64 [Val]   |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 617/617 [01:24<00:00, 7.33it/s]

================================================================================
                         Epoch 1/64 æ€»ç»“
================================================================================

[è®­ç»ƒ]
  - Total Loss: 3.8542
  - Reg Loss:   3.2156
  - Cls Loss:   0.6386

[éªŒè¯]
  - minADE: 2.1534 ç±³
  - minFDE: 3.4782 ç±³
  - MR:     35.24%

[ä¼˜åŒ–å™¨]
  - Learning Rate: 0.000100

ğŸ‰ æ–°çš„æœ€ä½³ minFDE: 3.4782 ç±³

âœ“ æœ€ä½³æ¨¡å‹å·²ä¿å­˜: outputs/checkpoints/best_dense_hivt.pth
  - minFDE: 3.4782 ç±³

================================================================================
```

## ğŸ”— ç›¸å…³æ–‡æ¡£

- **æ•°æ®é¢„å¤„ç†**ï¼š`0_README_preprocess_offline.md`
- **æ¨¡å‹è¯„ä¼°**ï¼š`2_README_val.md`
- **é¡¹ç›®ä¸»æ–‡æ¡£**ï¼š`../README.md`

## ğŸ“ æ›´æ–°æ—¥å¿—

- **v1.0** (2026-02-20)
  - åˆå§‹ç‰ˆæœ¬
  - æ”¯æŒ AMP è®­ç»ƒ
  - Warmup + Cosine å­¦ä¹ ç‡è°ƒåº¦
  - è‡ªåŠ¨ä¿å­˜æœ€ä½³æ¨¡å‹
  - TensorBoard é›†æˆ